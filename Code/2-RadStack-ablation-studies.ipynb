{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13364986,"sourceType":"datasetVersion","datasetId":8477983}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"267a5d2b","cell_type":"markdown","source":"\n# ðŸš€ Keystone Unsupervised Anomaly Detection â€” **Full Baselines + 20 Ablations (CV, Metrics, Plots, Models Saved)**\n\n**Target runtime:** up to ~6 hours on Kaggle Free **P100 GPU**  \n**What you get in one run:**\n- **Baselines:** B1 Static Threshold, B2 z-Score, B3 KMeans Distance, B4 Autoencoder (PyTorch if available)\n- **Core Models:** IsolationForest (IF), LOF (novelty), One-Class SVM (OCSVM), plus **Ensemble** (rank-average) and **Weighted Ensemble**\n- **20 Experiments (Ablations & Analyses)** exactly as listed\n- **Cross-Validation:** KFold(5) â€” synthetic labels generated **only on validation folds** (no leakage)\n- **Metrics:** Accuracy, Precision, Recall, F1, ROC-AUC, PR-AUC, Confusion Matrix counts\n- **Timing:** Fit and inference time (seconds)\n- **Policy:** Allow / Step-up / Deny, full threshold grid, expected-cost curve\n- **Explainability:** Permutation importance (lightweight) + optional SHAP (auto-detected)\n- **Robustness:** Noise & missing value stress, adversarial-style perturbations\n- **Scalability:** Subsample sizes (10kâ†’full) reports\n- **Generalization:** TimeSeriesSplit (if timestamp exists)\n- **Statistical Significance:** Bootstrap test on F1\n- **All models saved** under `/kaggle/working/models/<experiment_id>/`  \n- **All tables** saved as CSV + one **MASTER_RESULTS_FOR_PAPER.xlsx**  \n- **All plots** saved under `/kaggle/working/plots/`\n","metadata":{}},{"id":"83b78304","cell_type":"markdown","source":"## 1) Setup","metadata":{}},{"id":"20e25a79","cell_type":"code","source":"\nimport os, time, math, gc, warnings, json, itertools\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.svm import OneClassSVM\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import KFold, TimeSeriesSplit\nfrom sklearn.metrics import (precision_score, recall_score, f1_score, accuracy_score,\n                             confusion_matrix, roc_auc_score, average_precision_score)\n\nfrom scipy.stats import rankdata\n\n# Optional: PyTorch for Autoencoder baseline\ntry:\n    import torch\n    import torch.nn as nn\n    TORCH_OK = True\nexcept Exception:\n    TORCH_OK = False\n\n# Optional: SHAP (if present in Kaggle image). If not, we'll fall back to permutation importance.\ntry:\n    import shap\n    SHAP_OK = True\nexcept Exception:\n    SHAP_OK = False\n\ntry:\n    import joblib\n    JOBLIB_OK = True\nexcept Exception:\n    JOBLIB_OK = False\n\nOUT_DIR = \"/kaggle/working\"\nPLOT_DIR = os.path.join(OUT_DIR, \"plots\")\nMODEL_DIR = os.path.join(OUT_DIR, \"models\")\nos.makedirs(PLOT_DIR, exist_ok=True)\nos.makedirs(MODEL_DIR, exist_ok=True)\n\nDATA_PATH = \"/kaggle/input/communication-devstack-dataset/keystone_features_parsed_struct.csv\"\n\nrng = np.random.default_rng(42)\n\nprint(\"Torch available:\", TORCH_OK, \"| SHAP available:\", 'Yes' if 'shap' in globals() else False, \"| Joblib:\", JOBLIB_OK)\nprint(\"Output dirs:\", OUT_DIR, PLOT_DIR, MODEL_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T08:46:21.126928Z","iopub.execute_input":"2025-10-14T08:46:21.127436Z","iopub.status.idle":"2025-10-14T08:46:27.994366Z","shell.execute_reply.started":"2025-10-14T08:46:21.127411Z","shell.execute_reply":"2025-10-14T08:46:27.993359Z"}},"outputs":[{"name":"stdout","text":"Torch available: True | SHAP available: Yes | Joblib: True\nOutput dirs: /kaggle/working /kaggle/working/plots /kaggle/working/models\n","output_type":"stream"}],"execution_count":1},{"id":"f75b78b4","cell_type":"markdown","source":"## 2) Load & Prepare (Numeric Only for Models)","metadata":{}},{"id":"a76f0924","cell_type":"code","source":"\ndf = pd.read_csv(DATA_PATH)\nprint(\"Loaded:\", DATA_PATH, \"shape:\", df.shape)\n\n# Identify timestamp column if present\nTS_COL = None\nfor cand in ['timestamp','time','ts','datetime']:\n    if cand in df.columns:\n        TS_COL = cand\n        break\n\n# Numeric features for modeling\nnum_df = df.select_dtypes(include=[np.number]).copy()\nprint(\"Numeric features:\", num_df.shape[1])\n\n# Save EDA tables\nnum_df.describe().T.to_csv(os.path.join(OUT_DIR, \"eda_numeric_describe.csv\"))\ncorr = num_df.corr(numeric_only=True)\npairs = []\ncols = corr.columns.tolist()\nfor i in range(len(cols)):\n    for j in range(i+1, len(cols)):\n        pairs.append((cols[i], cols[j], float(corr.iloc[i,j])))\npairs = sorted(pairs, key=lambda x: abs(x[2]), reverse=True)[:20]\npd.DataFrame(pairs, columns=['feat_a','feat_b','rho']).to_csv(os.path.join(OUT_DIR, \"eda_top_corr_pairs.csv\"), index=False)\n\n# Quick hist for core columns (if present)\nfor c in [c for c in ['freq15_user','fail_ratio_user15','processing_time_ms'] if c in num_df.columns]:\n    plt.figure(figsize=(6,4)); plt.hist(num_df[c].dropna(), bins=50)\n    plt.title(f\"Histogram: {c}\"); plt.tight_layout()\n    plt.savefig(os.path.join(PLOT_DIR, f\"hist_{c}.png\")); plt.close()\n\n# Scalers\nSCALERS = {'standard': StandardScaler(), 'robust': RobustScaler(), 'minmax': MinMaxScaler()}\nDEFAULT_SCALER = 'standard'\nX_full = SCALERS[DEFAULT_SCALER].fit_transform(num_df.values)\nprint(\"X_full:\", X_full.shape, \"| Scaler:\", DEFAULT_SCALER)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T08:46:27.995634Z","iopub.execute_input":"2025-10-14T08:46:27.996054Z","iopub.status.idle":"2025-10-14T08:46:29.405553Z","shell.execute_reply.started":"2025-10-14T08:46:27.996028Z","shell.execute_reply":"2025-10-14T08:46:29.404682Z"}},"outputs":[{"name":"stdout","text":"Loaded: /kaggle/input/communication-devstack-dataset/keystone_features_parsed_struct.csv shape: (222308, 17)\nNumeric features: 12\nX_full: (222308, 12) | Scaler: standard\n","output_type":"stream"}],"execution_count":2},{"id":"e3b9618f","cell_type":"markdown","source":"## 3) Proxy Labels, Metrics, Model I/O Helpers","metadata":{}},{"id":"505ec53d","cell_type":"code","source":"\ndef inject_synthetic(X, frac=0.02, scale=4.0, seed=42):\n    rng = np.random.default_rng(seed)\n    n = X.shape[0]\n    k = max(1, int(n*frac)); k = min(k, max(1, n//2))\n    idx = rng.choice(n, size=k, replace=False)\n    X_syn = X[idx].copy()\n    noise = rng.normal(0.0, scale, size=X_syn.shape); X_syn += noise\n    y_syn = np.ones(k, dtype=int)\n    idx_norm = rng.choice(n, size=k, replace=False)\n    X_norm = X[idx_norm].copy()\n    y_norm = np.zeros(k, dtype=int)\n    X_eval = np.vstack([X_norm, X_syn])\n    y_eval = np.concatenate([y_norm, y_syn])\n    return X_eval, y_eval\n\ndef norm01(a, invert=False):\n    a = np.asarray(a, dtype=float)\n    if invert: a = -a\n    mn, mx = a.min(), a.max()\n    return (a - mn) / (mx - mn + 1e-12)\n\ndef eval_scores_to_metrics(y_true, score, threshold='median'):\n    s = np.asarray(score, dtype=float)\n    thr = np.median(s) if threshold=='median' else float(threshold)\n    y_pred = (s >= thr).astype(int)\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0,1]).ravel()\n    return {\n        'TP': int(tp), 'TN': int(tn), 'FP': int(fp), 'FN': int(fn),\n        'ACC': accuracy_score(y_true, y_pred),\n        'PREC': precision_score(y_true, y_pred, zero_division=0),\n        'REC': recall_score(y_true, y_pred, zero_division=0),\n        'F1': f1_score(y_true, y_pred, zero_division=0),\n        'ROC_AUC': roc_auc_score(y_true, s),\n        'PR_AUC': average_precision_score(y_true, s),\n    }\n\ndef time_fit_predict(model_fit_fn, Xtr, Xte, score_fn):\n    t0 = time.time(); model = model_fit_fn(Xtr); fit_t = time.time() - t0\n    t1 = time.time(); score = score_fn(model, Xte); infer_t = time.time() - t1\n    return model, score, fit_t, infer_t\n\ndef save_model(model, path):\n    if not JOBLIB_OK: return\n    os.makedirs(os.path.dirname(path), exist_ok=True)\n    joblib.dump(model, path)\n\ndef save_numpy(obj, path):\n    np.save(path, obj)\n\ndef save_json(obj, path):\n    with open(path, \"w\") as f: json.dump(obj, f, indent=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T08:46:29.406820Z","iopub.execute_input":"2025-10-14T08:46:29.407233Z","iopub.status.idle":"2025-10-14T08:46:29.417989Z","shell.execute_reply.started":"2025-10-14T08:46:29.407188Z","shell.execute_reply":"2025-10-14T08:46:29.417142Z"}},"outputs":[],"execution_count":3},{"id":"1b9c8f4e","cell_type":"markdown","source":"## 4) Models & Scorers","metadata":{}},{"id":"c83f9f12","cell_type":"code","source":"\nfrom sklearn.neighbors import LocalOutlierFactor as LOFNovel\n\n# IF\ndef fit_if(Xtr, contamination=0.08):\n    m = IsolationForest(contamination=contamination, random_state=42)\n    m.fit(Xtr); return m\ndef score_if(m, Xte):\n    return norm01(m.decision_function(Xte), invert=True)\n\n# LOF novelty\ndef fit_lof_novelty(Xtr, n_neighbors=35):\n    m = LOFNovel(n_neighbors=n_neighbors, novelty=True)\n    m.fit(Xtr); return m\ndef score_lof(m, Xte):\n    return norm01(-m.score_samples(Xte), invert=False)\n\n# OCSVM\ndef fit_ocsvm(Xtr, nu=0.08):\n    m = OneClassSVM(nu=nu, kernel='rbf', gamma='scale')\n    m.fit(Xtr); return m\ndef score_ocsvm(m, Xte):\n    return norm01(m.decision_function(Xte), invert=True)\n\n# KMeans baseline\ndef fit_kmeans(Xtr, k=8):\n    m = KMeans(n_clusters=k, n_init=10, random_state=42)\n    m.fit(Xtr); return m\ndef score_kmeans(m, Xte):\n    d = m.transform(Xte).min(axis=1)\n    return norm01(d, invert=False)\n\n# z-Score baseline\ndef score_zscore_univariate(Xtr, Xte):\n    mu = Xtr.mean(axis=0); sd = Xtr.std(axis=0) + 1e-12\n    z = np.abs((Xte - mu) / sd)\n    s = z.mean(axis=1)\n    return norm01(s, invert=False)\n\n# Autoencoder baseline (PyTorch)\nclass AE(nn.Module):\n    def __init__(self, d):\n        super().__init__()\n        h = max(16, d//2)\n        self.enc = nn.Sequential(nn.Linear(d, h), nn.ReLU(), nn.Linear(h, 8), nn.ReLU())\n        self.dec = nn.Sequential(nn.Linear(8, h), nn.ReLU(), nn.Linear(h, d))\n    def forward(self, x): return self.dec(self.enc(x))\n\ndef fit_autoencoder(Xtr, epochs=8, lr=1e-3, bs=256):\n    if not TORCH_OK: return None\n    d = Xtr.shape[1]\n    model = AE(d)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    opt = torch.optim.Adam(model.parameters(), lr=lr)\n    loss_fn = nn.MSELoss()\n    ds = torch.utils.data.TensorDataset(torch.tensor(Xtr, dtype=torch.float32))\n    dl = torch.utils.data.DataLoader(ds, batch_size=bs, shuffle=True)\n    model.train()\n    for _ in range(epochs):\n        for (xb,) in dl:\n            xb = xb.to(device)\n            opt.zero_grad(); loss = loss_fn(model(xb), xb); loss.backward(); opt.step()\n    return model.cpu()\n\ndef score_autoencoder(model, Xte):\n    if model is None: return None\n    with torch.no_grad():\n        x = torch.tensor(Xte, dtype=torch.float32)\n        recon = model(x).numpy()\n    err = ((Xte - recon)**2).mean(axis=1)\n    return norm01(err, invert=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T08:46:33.873704Z","iopub.execute_input":"2025-10-14T08:46:33.874436Z","iopub.status.idle":"2025-10-14T08:46:33.885834Z","shell.execute_reply.started":"2025-10-14T08:46:33.874410Z","shell.execute_reply":"2025-10-14T08:46:33.885126Z"}},"outputs":[],"execution_count":4},{"id":"de2077bf","cell_type":"markdown","source":"## 5) Cross-Validation for Baselines + Core Models (+ Save Models)","metadata":{}},{"id":"aa2e58e1","cell_type":"code","source":"\ndef run_cv_and_save(X, n_splits=5, exp_tag=\"core\"):\n    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n    rows = []\n    for fold, (tr, va) in enumerate(kf.split(X), 1):\n        Xtr, Xva = X[tr], X[va]\n        X_eval, y_eval = inject_synthetic(Xva, frac=0.04, scale=3.5, seed=fold+999)\n        base_dir = os.path.join(MODEL_DIR, f\"{exp_tag}_fold{fold}\")\n        os.makedirs(base_dir, exist_ok=True)\n\n        # IF\n        m_if, s_if, ft_if, it_if = time_fit_predict(lambda Xt: fit_if(Xt, 0.08), Xtr, X_eval, score_if)\n        save_model(m_if, os.path.join(base_dir,\"IF.pkl\"))\n        rows.append(dict(Model='IF', Fold=fold, FitSec=ft_if, InferSec=it_if, **eval_scores_to_metrics(y_eval, s_if)))\n\n        # LOF\n        m_lof, s_lof, ft_lof, it_lof = time_fit_predict(lambda Xt: fit_lof_novelty(Xt, 35), Xtr, X_eval, score_lof)\n        save_model(m_lof, os.path.join(base_dir,\"LOF.pkl\"))\n        rows.append(dict(Model='LOF', Fold=fold, FitSec=ft_lof, InferSec=it_lof, **eval_scores_to_metrics(y_eval, s_lof)))\n\n        # OCSVM\n        m_svm, s_svm, ft_svm, it_svm = time_fit_predict(lambda Xt: fit_ocsvm(Xt, 0.08), Xtr, X_eval, score_ocsvm)\n        save_model(m_svm, os.path.join(base_dir,\"OCSVM.pkl\"))\n        rows.append(dict(Model='OCSVM', Fold=fold, FitSec=ft_svm, InferSec=it_svm, **eval_scores_to_metrics(y_eval, s_svm)))\n\n        # KMeans\n        m_km, s_km, ft_km, it_km = time_fit_predict(lambda Xt: fit_kmeans(Xt, 8), Xtr, X_eval, score_kmeans)\n        save_model(m_km, os.path.join(base_dir,\"KMeans.pkl\"))\n        rows.append(dict(Model='KMeans', Fold=fold, FitSec=ft_km, InferSec=it_km, **eval_scores_to_metrics(y_eval, s_km)))\n\n        # z-Score (no model, save params)\n        t0 = time.time(); s_z = score_zscore_univariate(Xtr, X_eval); it_z = time.time()-t0\n        rows.append(dict(Model='zScore', Fold=fold, FitSec=0.0, InferSec=it_z, **eval_scores_to_metrics(y_eval, s_z)))\n        if JOBLIB_OK:\n            joblib.dump({'mean':Xtr.mean(axis=0), 'std':Xtr.std(axis=0)}, os.path.join(base_dir,\"zscore_params.pkl\"))\n\n        # Autoencoder\n        if TORCH_OK:\n            m_ae, s_ae, ft_ae, it_ae = time_fit_predict(lambda Xt: fit_autoencoder(Xt, 8), Xtr, X_eval, score_autoencoder)\n            if s_ae is not None:\n                torch.save(m_ae.state_dict(), os.path.join(base_dir, \"AE.pt\"))\n                rows.append(dict(Model='Autoencoder', Fold=fold, FitSec=ft_ae, InferSec=it_ae, **eval_scores_to_metrics(y_eval, s_ae)))\n\n        # Ensemble (rank-average IF, LOF, OCSVM)\n        S = np.vstack([s_if, s_lof, s_svm]).T\n        ranks = np.vstack([rankdata(S[:,i]) for i in range(S.shape[1])]).T\n        ens = (ranks.mean(axis=1) - ranks.min())/(ranks.max()-ranks.min()+1e-12)\n        rows.append(dict(Model='Ensemble', Fold=fold, FitSec=ft_if+ft_lof+ft_svm, InferSec=it_if+it_lof+it_svm, **eval_scores_to_metrics(y_eval, ens)))\n\n        # Weighted Ensemble (A8)\n        w = np.array([0.5, 0.2, 0.3])  # IF, LOF, OCSVM\n        ens_w = norm01(np.dot(S, w), invert=False)\n        rows.append(dict(Model='WeightedEnsemble', Fold=fold, FitSec=ft_if+ft_lof+ft_svm, InferSec=it_if+it_lof+it_svm, **eval_scores_to_metrics(y_eval, ens_w)))\n\n    df_cv = pd.DataFrame(rows)\n    df_cv.to_csv(os.path.join(OUT_DIR, f\"{exp_tag}_cv_metrics_by_fold.csv\"), index=False)\n    df_cv.groupby('Model').agg(['mean','std']).to_csv(os.path.join(OUT_DIR, f\"{exp_tag}_cv_metrics_summary.csv\"))\n    return df_cv\n\ncv_core = run_cv_and_save(X_full, 5, \"core\")\ncv_core.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T17:00:35.940540Z","iopub.execute_input":"2025-10-13T17:00:35.940791Z","iopub.status.idle":"2025-10-13T17:31:21.857260Z","shell.execute_reply.started":"2025-10-13T17:00:35.940773Z","shell.execute_reply":"2025-10-13T17:31:21.856654Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"    Model  Fold      FitSec  InferSec    TP    TN   FP   FN       ACC  \\\n0      IF     1    3.582123  0.104666  1568  1567  211  210  0.881609   \n1     LOF     1   68.141158  1.464135  1754  1754   24   24  0.986502   \n2   OCSVM     1  215.725059  2.056618  1772  1772    6    6  0.996625   \n3  KMeans     1    0.962621  0.001304  1773  1773    5    5  0.997188   \n4  zScore     1    0.000000  0.019973  1778  1778    0    0  1.000000   \n\n       PREC       REC        F1   ROC_AUC    PR_AUC  \n0  0.881394  0.881890  0.881642  0.957722  0.954712  \n1  0.986502  0.986502  0.986502  0.995073  0.993161  \n2  0.996625  0.996625  0.996625  0.999810  0.999801  \n3  0.997188  0.997188  0.997188  0.998473  0.992090  \n4  1.000000  1.000000  1.000000  1.000000  1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Fold</th>\n      <th>FitSec</th>\n      <th>InferSec</th>\n      <th>TP</th>\n      <th>TN</th>\n      <th>FP</th>\n      <th>FN</th>\n      <th>ACC</th>\n      <th>PREC</th>\n      <th>REC</th>\n      <th>F1</th>\n      <th>ROC_AUC</th>\n      <th>PR_AUC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>IF</td>\n      <td>1</td>\n      <td>3.582123</td>\n      <td>0.104666</td>\n      <td>1568</td>\n      <td>1567</td>\n      <td>211</td>\n      <td>210</td>\n      <td>0.881609</td>\n      <td>0.881394</td>\n      <td>0.881890</td>\n      <td>0.881642</td>\n      <td>0.957722</td>\n      <td>0.954712</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LOF</td>\n      <td>1</td>\n      <td>68.141158</td>\n      <td>1.464135</td>\n      <td>1754</td>\n      <td>1754</td>\n      <td>24</td>\n      <td>24</td>\n      <td>0.986502</td>\n      <td>0.986502</td>\n      <td>0.986502</td>\n      <td>0.986502</td>\n      <td>0.995073</td>\n      <td>0.993161</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>OCSVM</td>\n      <td>1</td>\n      <td>215.725059</td>\n      <td>2.056618</td>\n      <td>1772</td>\n      <td>1772</td>\n      <td>6</td>\n      <td>6</td>\n      <td>0.996625</td>\n      <td>0.996625</td>\n      <td>0.996625</td>\n      <td>0.996625</td>\n      <td>0.999810</td>\n      <td>0.999801</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>KMeans</td>\n      <td>1</td>\n      <td>0.962621</td>\n      <td>0.001304</td>\n      <td>1773</td>\n      <td>1773</td>\n      <td>5</td>\n      <td>5</td>\n      <td>0.997188</td>\n      <td>0.997188</td>\n      <td>0.997188</td>\n      <td>0.997188</td>\n      <td>0.998473</td>\n      <td>0.992090</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>zScore</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.019973</td>\n      <td>1778</td>\n      <td>1778</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"id":"15a94989","cell_type":"markdown","source":"## 6) Policy Threshold Grid & Expected Cost (A9)","metadata":{}},{"id":"494e1b09","cell_type":"code","source":"\n# Fit ensemble components on FULL data (unlabeled)\niso_full = IsolationForest(contamination=0.08, random_state=42).fit(X_full)\nlof_full = LocalOutlierFactor(n_neighbors=35, novelty=True).fit(X_full)\nsvm_full = OneClassSVM(nu=0.08, kernel='rbf', gamma='scale').fit(X_full)\n\ndef ens_scores_full():\n    s_if = norm01(iso_full.decision_function(X_full), invert=True)\n    s_lof = norm01(-lof_full.score_samples(X_full), invert=False)\n    s_svm = norm01(svm_full.decision_function(X_full), invert=True)\n    R = np.vstack([rankdata(s_if), rankdata(s_lof), rankdata(s_svm)]).T\n    ens = (R.mean(axis=1) - R.min())/(R.max()-R.min()+1e-12)\n    ens_w = norm01(np.dot(np.vstack([s_if,s_lof,s_svm]).T, np.array([0.5,0.2,0.3])))\n    return s_if, s_lof, s_svm, ens, ens_w\ns_if_full, s_lof_full, s_svm_full, ens_full, ensw_full = ens_scores_full()\n\ndef decisions_from_score(s, t1=0.30, t2=0.60):\n    s = np.asarray(s)\n    dec = np.full(len(s), 'Allow', dtype=object)\n    dec[(s >= t1) & (s < t2)] = 'Step-up'\n    dec[s >= t2] = 'Deny'\n    return dec\n\nC_false_allow, C_step_up, C_deny_false = 100.0, 2.0, 20.0\nproxy_base = 0.08\nthr = np.quantile(ens_full, 1 - proxy_base)\nproxy_labels = (ens_full >= thr).astype(int)  # NOT used for training\n\ndef expected_cost(decisions, proxy_labels):\n    normal = (proxy_labels == 0); anom = (proxy_labels == 1)\n    allow = (decisions == 'Allow'); step = (decisions == 'Step-up'); deny = (decisions == 'Deny')\n    return float((allow & anom).sum()*C_false_allow + step.sum()*C_step_up + (deny & normal).sum()*C_deny_false)\n\n# Grid sweep\ngrid = []\nfor t1 in np.linspace(0.05, 0.5, 10):\n    for t2 in np.linspace(t1+0.05, 0.95, 10):\n        de = decisions_from_score(ens_full, t1, t2)\n        d = pd.value_counts(de, normalize=True)\n        grid.append((t1, t2, float(d.get('Allow',0))*100, float(d.get('Step-up',0))*100, float(d.get('Deny',0))*100, expected_cost(de, proxy_labels)))\ngrid_df = pd.DataFrame(grid, columns=['t1','t2','allow%','step%','deny%','expected_cost']).sort_values('expected_cost')\ngrid_df.to_csv(os.path.join(OUT_DIR, \"policy_frontier_grid.csv\"), index=False)\n\nplt.figure(figsize=(8,4)); plt.plot(range(20), grid_df['expected_cost'].values[:20], marker='o')\nplt.title(\"Top-20 Policies by Expected Cost\"); plt.xlabel(\"Rank\"); plt.ylabel(\"Expected Cost\")\nplt.tight_layout(); plt.savefig(os.path.join(PLOT_DIR, \"policy_top20_cost.png\")); plt.close()\n\npd.DataFrame({'Decision':['Allow','Step-up','Deny'],\n              'Percent': pd.value_counts(decisions_from_score(ens_full, 0.30, 0.60), normalize=True).reindex(['Allow','Step-up','Deny']).fillna(0).values*100\n             }).to_csv(os.path.join(OUT_DIR, \"policy_distribution.csv\"), index=False)\n\n# Save core full-data models\nif JOBLIB_OK:\n    joblib.dump(iso_full, os.path.join(MODEL_DIR, \"full_IF.pkl\"))\n    joblib.dump(lof_full, os.path.join(MODEL_DIR, \"full_LOF.pkl\"))\n    joblib.dump(svm_full, os.path.join(MODEL_DIR, \"full_OCSVM.pkl\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T08:48:13.886330Z","iopub.execute_input":"2025-10-14T08:48:13.886949Z","iopub.status.idle":"2025-10-14T09:02:22.139246Z","shell.execute_reply.started":"2025-10-14T08:48:13.886925Z","shell.execute_reply":"2025-10-14T09:02:22.138417Z"}},"outputs":[],"execution_count":6},{"id":"0788abb5","cell_type":"markdown","source":"## 7) Feature-Drop Ablations (A2â€“A5) + Scaling (A7) â€” CV & Save Models","metadata":{}},{"id":"b4d08b2c","cell_type":"code","source":"\ndef ablation_cv(X_df, drop_cols=None, scaler_name='standard', folds=5, exp_tag=\"ablation\"):\n    # Drop columns by name if present (from numeric df)\n    if drop_cols:\n        keep = [c for c in X_df.columns if c not in drop_cols]\n    else:\n        keep = list(X_df.columns)\n    Xsub = SCALERS[scaler_name].fit_transform(X_df[keep].values)\n    kf = KFold(n_splits=folds, shuffle=True, random_state=202)\n    rows = []\n    for fold, (tr, va) in enumerate(kf.split(Xsub), 1):\n        Xtr, Xva = Xsub[tr], Xsub[va]\n        X_eval, y_eval = inject_synthetic(Xva, frac=0.04, scale=3.5, seed=fold+1234)\n        base_dir = os.path.join(MODEL_DIR, f\"{exp_tag}_{scaler_name}_fold{fold}\")\n        os.makedirs(base_dir, exist_ok=True)\n\n        # Use IF as ablation sentinel model (fast & robust)\n        m_if, s_if, ft_if, it_if = time_fit_predict(lambda Xt: fit_if(Xt, 0.08), Xtr, X_eval, score_if)\n        save_model(m_if, os.path.join(base_dir,\"IF.pkl\"))\n        rows.append(dict(Experiment=exp_tag, Scaler=scaler_name, Fold=fold, Model='IF',\n                         FitSec=ft_if, InferSec=it_if, **eval_scores_to_metrics(y_eval, s_if)))\n    out_df = pd.DataFrame(rows)\n    out_df.to_csv(os.path.join(OUT_DIR, f\"{exp_tag}_{scaler_name}_cv.csv\"), index=False)\n    return out_df\n\n# Define feature groups (only those existing)\nBEH = [c for c in ['freq15_user','fail_ratio_user15'] if c in num_df.columns]\nSYS = [c for c in ['processing_time_ms','response_size_bytes','core_switches','vars_size_bytes'] if c in num_df.columns]\nSEM = [c for c in ['endpoint_class','resource_sensitivity','method'] if c in num_df.columns]\nTMP = [c for c in ['hour','wday','is_off_hours'] if c in num_df.columns]\n\nabl_tables = []\nabl_tables.append(ablation_cv(num_df, drop_cols=BEH, scaler_name='standard', exp_tag=\"A2_drop_behavioral\"))\nabl_tables.append(ablation_cv(num_df, drop_cols=SYS, scaler_name='standard', exp_tag=\"A3_drop_system\"))\nabl_tables.append(ablation_cv(num_df, drop_cols=SEM, scaler_name='standard', exp_tag=\"A4_drop_semantic\"))\nabl_tables.append(ablation_cv(num_df, drop_cols=TMP, scaler_name='standard', exp_tag=\"A5_drop_temporal\"))\nfor scn in ['standard','robust','minmax']:\n    abl_tables.append(ablation_cv(num_df, drop_cols=None, scaler_name=scn, exp_tag=f\"A7_scaler_{scn}\"))\n\npd.concat(abl_tables, ignore_index=True).to_csv(os.path.join(OUT_DIR, \"ablations_A2_A5_A7_summary.csv\"), index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T17:45:20.579791Z","iopub.execute_input":"2025-10-13T17:45:20.579965Z","iopub.status.idle":"2025-10-13T17:47:22.450281Z","shell.execute_reply.started":"2025-10-13T17:45:20.579951Z","shell.execute_reply":"2025-10-13T17:47:22.449525Z"}},"outputs":[],"execution_count":7},{"id":"72c4503a","cell_type":"markdown","source":"## 8) Sensitivity (A6) â€” Contamination (IF) Ã— nu (OCSVM) Grid","metadata":{}},{"id":"5b7b19ef","cell_type":"code","source":"\nrows = []\nkf = KFold(n_splits=3, shuffle=True, random_state=321)  # 3-fold to save time\nfor contam in [0.03,0.08,0.12]:\n    for nu in [0.03,0.08,0.12]:\n        for fold, (tr, va) in enumerate(kf.split(X_full), 1):\n            Xtr, Xva = X_full[tr], X_full[va]\n            X_eval, y_eval = inject_synthetic(Xva, frac=0.04, scale=3.5, seed=fold+500)\n            # IF score\n            m_if = fit_if(Xtr, contamination=contam)\n            s_if = score_if(m_if, X_eval)\n            # OCSVM score\n            m_svm = fit_ocsvm(Xtr, nu=nu)\n            s_svm = score_ocsvm(m_svm, X_eval)\n            # LOF fixed\n            m_lof = fit_lof_novelty(Xtr, 35); s_lof = score_lof(m_lof, X_eval)\n            # Ensemble\n            S = np.vstack([s_if, s_lof, s_svm]).T\n            ranks = np.vstack([rankdata(S[:,i]) for i in range(S.shape[1])]).T\n            ens = (ranks.mean(axis=1)-ranks.min())/(ranks.max()-ranks.min()+1e-12)\n            metrics = eval_scores_to_metrics(y_eval, ens)\n            rows.append(dict(contamination=contam, nu=nu, fold=fold, **metrics))\nsens_df = pd.DataFrame(rows)\nsens_df.to_csv(os.path.join(OUT_DIR, \"A6_sensitivity_grid.csv\"), index=False)\nsens_pivot = sens_df.pivot_table(index='contamination', columns='nu', values='F1', aggfunc='mean')\nplt.figure(figsize=(6,4)); plt.imshow(sens_pivot, aspect='auto'); plt.colorbar(label='Mean F1')\nplt.xticks(range(len(sens_pivot.columns)), sens_pivot.columns); plt.yticks(range(len(sens_pivot.index)), sens_pivot.index)\nplt.title(\"A6 Sensitivity: F1 vs (contam, nu)\")\nplt.tight_layout(); plt.savefig(os.path.join(PLOT_DIR, \"A6_sensitivity_heatmap.png\")); plt.close()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T09:02:22.140436Z","iopub.execute_input":"2025-10-14T09:02:22.140756Z","iopub.status.idle":"2025-10-14T11:06:24.476642Z","shell.execute_reply.started":"2025-10-14T09:02:22.140736Z","shell.execute_reply":"2025-10-14T11:06:24.476049Z"}},"outputs":[],"execution_count":7},{"id":"b4baa274","cell_type":"markdown","source":"## 9) Model Disagreement (A10) â€” Jaccard Overlap of Topâ€‘k%","metadata":{}},{"id":"ee92dcbb","cell_type":"code","source":"\ndef topk_set(scores, pct=1.0):\n    k = max(1, int(len(scores)*pct/100.0)); return set(np.argsort(scores)[-k:])\n\nK_list = [0.5, 1, 2, 5, 10]\nrows = []\n# Use full-data scores\nIFs, LOFs, SVMs, ENS, ENSW = s_if_full, s_lof_full, s_svm_full, ens_full, ensw_full\nfor k in K_list:\n    Si, Sl, Ss, Se, Sew = [topk_set(s, k) for s in [IFs, LOFs, SVMs, ENS, ENSW]]\n    def j(a,b): \n        return len(a&b)/max(1,len(a|b))\n    rows.append(dict(kpct=k,\n                     IF_LOF=j(Si,Sl), IF_SVM=j(Si,Ss), LOF_SVM=j(Sl,Ss),\n                     ENS_IF=j(Se,Si), ENS_LOF=j(Se,Sl), ENS_SVM=j(Se,Ss),\n                     ENSW_ENS=j(Sew,Se)))\npd.DataFrame(rows).to_csv(os.path.join(OUT_DIR, \"A10_model_disagreement.csv\"), index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T11:17:26.340652Z","iopub.execute_input":"2025-10-14T11:17:26.341193Z","iopub.status.idle":"2025-10-14T11:17:26.674030Z","shell.execute_reply.started":"2025-10-14T11:17:26.341171Z","shell.execute_reply":"2025-10-14T11:17:26.673258Z"}},"outputs":[],"execution_count":9},{"id":"6e13ad7b","cell_type":"markdown","source":"## 10) A11 Efficiency â€” Already Captured in CV Fit/Infer Times","metadata":{}},{"id":"33bb69af","cell_type":"code","source":"print('A11 captured via FitSec/InferSec in CV tables.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T11:17:33.863612Z","iopub.execute_input":"2025-10-14T11:17:33.864086Z","iopub.status.idle":"2025-10-14T11:17:33.867849Z","shell.execute_reply.started":"2025-10-14T11:17:33.864065Z","shell.execute_reply":"2025-10-14T11:17:33.867198Z"}},"outputs":[{"name":"stdout","text":"A11 captured via FitSec/InferSec in CV tables.\n","output_type":"stream"}],"execution_count":10},{"id":"6ee0e30f","cell_type":"markdown","source":"## 11) A12/A17 Explainability â€” Permutation Importance (+ optional SHAP)","metadata":{}},{"id":"96273c41","cell_type":"code","source":"\ndef permutation_importance(model, X, score_func, n_repeats=5, subsample=5000, seed=123):\n    rng = np.random.default_rng(seed)\n    n = X.shape[0]\n    idx = rng.choice(n, size=min(subsample, n), replace=False)\n    Xs = X[idx].copy()\n    base = score_func(model, Xs)\n    base_var = np.var(base)\n    importances = []\n    for j in range(Xs.shape[1]):\n        imp = []\n        Xtmp = Xs.copy()\n        for _ in range(n_repeats):\n            rng.shuffle(Xtmp[:,j])\n            s = score_func(model, Xtmp)\n            imp.append(max(0.0, np.var(s) - base_var))\n        importances.append(np.mean(imp))\n    imp = np.array(importances)\n    return imp / (imp.sum() + 1e-12)\n\n# Use full IsolationForest for importance since Tree-based\nimp = permutation_importance(iso_full, X_full, lambda m, Xt: norm01(m.decision_function(Xt), invert=True), n_repeats=3, subsample=4000)\nfeat_imp = pd.DataFrame({'feature': num_df.columns, 'perm_importance': imp}).sort_values('perm_importance', ascending=False)\nfeat_imp.to_csv(os.path.join(OUT_DIR, \"A12_perm_importance_IF.csv\"), index=False)\n\nplt.figure(figsize=(7,6))\ntop = feat_imp.head(20).iloc[::-1]\nplt.barh(top['feature'], top['perm_importance'])\nplt.title(\"Permutation Importance (IF) â€” Top 20\")\nplt.tight_layout(); plt.savefig(os.path.join(PLOT_DIR, \"A12_perm_importance_top20.png\")); plt.close()\n\n# Optional: SHAP for IF (TreeExplainer), if shap installed\nif 'shap' in globals():\n    try:\n        explainer = shap.TreeExplainer(iso_full)\n        samp = min(3000, X_full.shape[0])\n        Xs = X_full[:samp]\n        sv = explainer.shap_values(Xs)\n        shap.summary_plot(sv, Xs, feature_names=list(num_df.columns), show=False)\n        plt.tight_layout(); plt.savefig(os.path.join(PLOT_DIR, \"A17_shap_summary_IF.png\")); plt.close()\n    except Exception as e:\n        print(\"SHAP failed, used permutation importance instead:\", e)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T11:19:04.400969Z","iopub.execute_input":"2025-10-14T11:19:04.401585Z","iopub.status.idle":"2025-10-14T11:19:13.282728Z","shell.execute_reply.started":"2025-10-14T11:19:04.401562Z","shell.execute_reply":"2025-10-14T11:19:13.281862Z"}},"outputs":[],"execution_count":12},{"id":"049d99e3","cell_type":"markdown","source":"## 12) A13 Robustness â€” Noise / Missing Stress Tests","metadata":{}},{"id":"64d7cfa8","cell_type":"code","source":"\ndef robustness_test(X, noise_scales=[0.5,1.0,2.0], missing_fracs=[0.01,0.05,0.1]):\n    rows = []\n    for ns in noise_scales:\n        Xn = X.copy(); Xn += rng.normal(0, ns, size=Xn.shape)\n        s_if = norm01(iso_full.decision_function(Xn), invert=True)\n        rows.append(dict(test='noise', level=ns, var=np.var(s_if), mean=s_if.mean()))\n    for mf in missing_fracs:\n        Xm = X.copy()\n        m = rng.random(size=Xm.shape) < mf\n        Xm[m] = np.nan\n        # simple impute by column mean (avoid leakage by using full-data mean â€” unsupervised global)\n        colmean = np.nanmean(Xm, axis=0); idxs = np.where(np.isnan(Xm))\n        Xm[idxs] = np.take(colmean, idxs[1])\n        s_if = norm01(iso_full.decision_function(Xm), invert=True)\n        rows.append(dict(test='missing', level=mf, var=np.var(s_if), mean=s_if.mean()))\n    return pd.DataFrame(rows)\n\nrob_df = robustness_test(X_full)\nrob_df.to_csv(os.path.join(OUT_DIR, \"A13_robustness.csv\"), index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T11:20:10.791593Z","iopub.execute_input":"2025-10-14T11:20:10.792101Z","iopub.status.idle":"2025-10-14T11:20:41.864240Z","shell.execute_reply.started":"2025-10-14T11:20:10.792077Z","shell.execute_reply":"2025-10-14T11:20:41.863664Z"}},"outputs":[],"execution_count":13},{"id":"88647764","cell_type":"markdown","source":"## 13) A14 Adversarial â€” Evasion-Style Perturbations","metadata":{}},{"id":"dc3fd916","cell_type":"code","source":"\ndef adversarial_evasion_score(m, X, max_iter=3, eps=0.1):\n    # Simple gradient-free: jitter features towards global mean to reduce anomaly score\n    Xadv = X.copy()\n    mu = X.mean(axis=0)\n    for _ in range(max_iter):\n        delta = np.sign(mu - Xadv) * eps\n        Xadv = Xadv + delta\n    s = norm01(m.decision_function(Xadv), invert=True)\n    return s\n\ns_base = norm01(iso_full.decision_function(X_full), invert=True)\ns_adv  = adversarial_evasion_score(iso_full, X_full, max_iter=5, eps=0.02)\npd.DataFrame({'base_mean':[float(s_base.mean())], 'adv_mean':[float(s_adv.mean())]}).to_csv(os.path.join(OUT_DIR,\"A14_adversarial_summary.csv\"), index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T11:20:49.875031Z","iopub.execute_input":"2025-10-14T11:20:49.875297Z","iopub.status.idle":"2025-10-14T11:20:59.390030Z","shell.execute_reply.started":"2025-10-14T11:20:49.875279Z","shell.execute_reply":"2025-10-14T11:20:59.389258Z"}},"outputs":[],"execution_count":14},{"id":"bf7a9401","cell_type":"markdown","source":"## 14) A15 Scalability â€” Subsample Sizes Timing","metadata":{}},{"id":"69c10f9a","cell_type":"code","source":"\nsizes = [10000, 50000, 100000, min(200000, X_full.shape[0]), X_full.shape[0]]\nrows = []\nfor n in sizes:\n    Xs = X_full[:n]\n    t0=time.time(); m=IsolationForest(contamination=0.08, random_state=42).fit(Xs); t_fit=time.time()-t0\n    t1=time.time(); _=m.decision_function(Xs); t_inf=time.time()-t1\n    rows.append(dict(N=n, FitSec=t_fit, InferSec=t_inf))\nscal_df = pd.DataFrame(rows)\nscal_df.to_csv(os.path.join(OUT_DIR, \"A15_scalability.csv\"), index=False)\nplt.figure(figsize=(7,4)); plt.plot(scal_df['N'], scal_df['FitSec'], marker='o', label='Fit')\nplt.plot(scal_df['N'], scal_df['InferSec'], marker='s', label='Infer'); plt.legend()\nplt.title(\"A15 Scalability â€” IF Timing vs N\"); plt.xlabel(\"N\"); plt.ylabel(\"Seconds\")\nplt.tight_layout(); plt.savefig(os.path.join(PLOT_DIR, \"A15_scalability.png\")); plt.close()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T11:29:48.566967Z","iopub.execute_input":"2025-10-14T11:29:48.567594Z","iopub.status.idle":"2025-10-14T11:30:13.494691Z","shell.execute_reply.started":"2025-10-14T11:29:48.567572Z","shell.execute_reply":"2025-10-14T11:30:13.494119Z"}},"outputs":[],"execution_count":22},{"id":"d51b83c3","cell_type":"markdown","source":"## 15) A16 Generalization â€” TimeSeriesSplit if timestamp present","metadata":{}},{"id":"dcc89b1a","cell_type":"code","source":"\ngen_rows = []\nif TS_COL is not None:\n    try:\n        df_sorted = df.sort_values(TS_COL).reset_index(drop=True)\n        X_ts = SCALERS['standard'].fit_transform(df_sorted.select_dtypes(include=[np.number]).values)\n        tscv = TimeSeriesSplit(n_splits=5)\n        for fold, (tr, va) in enumerate(tscv.split(X_ts), 1):\n            Xtr, Xva = X_ts[tr], X_ts[va]\n            X_eval, y_eval = inject_synthetic(Xva, frac=0.04, scale=3.5, seed=fold+2121)\n            m_if = fit_if(Xtr, 0.08); s_if = score_if(m_if, X_eval)\n            gen_rows.append(dict(Fold=fold, **eval_scores_to_metrics(y_eval, s_if)))\n        pd.DataFrame(gen_rows).to_csv(os.path.join(OUT_DIR, \"A16_timeseries_generalization.csv\"), index=False)\n    except Exception as e:\n        print(\"A16 TimeSeriesSplit failed:\", e)\nelse:\n    print(\"A16 skipped: No timestamp column detected.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T11:21:43.155717Z","iopub.execute_input":"2025-10-14T11:21:43.155989Z","iopub.status.idle":"2025-10-14T11:21:56.119020Z","shell.execute_reply.started":"2025-10-14T11:21:43.155969Z","shell.execute_reply":"2025-10-14T11:21:56.118262Z"}},"outputs":[],"execution_count":15},{"id":"e9e7edfc","cell_type":"markdown","source":"## 16) A18/A19 Metrics & Confusion Matrices â€” Provided by CV Tables","metadata":{}},{"id":"12ddc34b","cell_type":"code","source":"print('A18/A19 included in CV outputs core_cv_metrics_by_fold.csv & summary.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T11:21:59.819590Z","iopub.execute_input":"2025-10-14T11:21:59.819857Z","iopub.status.idle":"2025-10-14T11:21:59.823943Z","shell.execute_reply.started":"2025-10-14T11:21:59.819838Z","shell.execute_reply":"2025-10-14T11:21:59.823160Z"}},"outputs":[{"name":"stdout","text":"A18/A19 included in CV outputs core_cv_metrics_by_fold.csv & summary.\n","output_type":"stream"}],"execution_count":16},{"id":"952fbab3","cell_type":"markdown","source":"## 17) A20 Statistical Significance â€” Bootstrap on F1","metadata":{}},{"id":"905838b3","cell_type":"code","source":"\n# Compare Ensemble vs best single (IF) using bootstrap over folds\ncore = pd.read_csv(os.path.join(OUT_DIR, \"/kaggle/input/communication-devstack-dataset/core_cv_metrics_by_fold.csv\"))\nens = core[core['Model']=='Ensemble']['F1'].values\niff = core[core['Model']=='IF']['F1'].values\nB=2000; rng = np.random.default_rng(1234); diffs=[]\nfor _ in range(B):\n    idx = rng.integers(0, len(ens), len(ens))\n    diffs.append((ens[idx] - iff[idx]).mean())\npval = (np.sum(np.array(diffs) <= 0) + 1) / (B + 1)\npd.DataFrame({'mean_diff':[float(np.mean(diffs))], 'p_value':[float(pval)]}).to_csv(os.path.join(OUT_DIR,\"A20_bootstrap_ens_vs_if.csv\"), index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T11:24:03.916954Z","iopub.execute_input":"2025-10-14T11:24:03.917719Z","iopub.status.idle":"2025-10-14T11:24:03.962326Z","shell.execute_reply.started":"2025-10-14T11:24:03.917694Z","shell.execute_reply":"2025-10-14T11:24:03.961674Z"}},"outputs":[],"execution_count":18},{"id":"4a0ea92a","cell_type":"markdown","source":"## 18) MASTER workbook export (all key outputs)","metadata":{}},{"id":"4a91bac7","cell_type":"code","source":"\nmaster_xlsx = os.path.join(OUT_DIR, \"MASTER_RESULTS_FOR_PAPER.xlsx\")\nwith pd.ExcelWriter(master_xlsx) as xl:\n    # Core CV\n    pd.read_csv(os.path.join(OUT_DIR, \"/kaggle/input/communication-devstack-dataset/core_cv_metrics_by_fold.csv\")).to_excel(xl, sheet_name=\"core_cv_by_fold\", index=False)\n    pd.read_csv(os.path.join(OUT_DIR, \"/kaggle/input/communication-devstack-dataset/core_cv_metrics_summary.csv\")).to_excel(xl, sheet_name=\"core_cv_summary\", index=False)\n    # Ablations A2-A5, A7\n    pd.read_csv(os.path.join(OUT_DIR, \"/kaggle/input/communication-devstack-dataset/ablations_A2_A5_A7_summary.csv\")).to_excel(xl, sheet_name=\"ablations_A2_A5_A7\", index=False)\n    # Policy\n    pd.read_csv(os.path.join(OUT_DIR, \"/kaggle/input/communication-devstack-dataset/policy_frontier_grid.csv\")).to_excel(xl, sheet_name=\"policy_frontier\", index=False)\n    pd.read_csv(os.path.join(OUT_DIR, \"/kaggle/input/communication-devstack-dataset/policy_distribution.csv\")).to_excel(xl, sheet_name=\"policy_dist\", index=False)\n    # Sensitivity\n    pd.read_csv(os.path.join(OUT_DIR, \"/kaggle/input/communication-devstack-dataset/A6_sensitivity_grid.csv\")).to_excel(xl, sheet_name=\"A6_sensitivity\", index=False)\n    # Disagreement\n    pd.read_csv(os.path.join(OUT_DIR, \"/kaggle/input/communication-devstack-dataset/A10_model_disagreement.csv\")).to_excel(xl, sheet_name=\"A10_disagreement\", index=False)\n    # Robustness\n    pd.read_csv(os.path.join(OUT_DIR, \"/kaggle/input/communication-devstack-dataset/A13_robustness.csv\")).to_excel(xl, sheet_name=\"A13_robustness\", index=False)\n    # Adversarial\n    pd.read_csv(os.path.join(OUT_DIR, \"/kaggle/input/communication-devstack-dataset/A14_adversarial_summary.csv\")).to_excel(xl, sheet_name=\"A14_adversarial\", index=False)\n    # Scalability\n    pd.read_csv(os.path.join(OUT_DIR, \"/kaggle/input/communication-devstack-dataset/A15_scalability.csv\")).to_excel(xl, sheet_name=\"A15_scalability\", index=False)\n    # Generalization (if exists)\n    p = os.path.join(OUT_DIR, \"/kaggle/input/communication-devstack-dataset/A16_timeseries_generalization.csv\")\n    if os.path.exists(p):\n        pd.read_csv(p).to_excel(xl, sheet_name=\"A16_timeseries\", index=False)\n    # EDA\n    pd.read_csv(os.path.join(OUT_DIR, \"/kaggle/input/communication-devstack-dataset/eda_numeric_describe.csv\")).to_excel(xl, sheet_name=\"eda_describe\", index=False)\n    pd.read_csv(os.path.join(OUT_DIR, \"/kaggle/input/communication-devstack-dataset/eda_top_corr_pairs.csv\")).to_excel(xl, sheet_name=\"eda_corr_pairs\", index=False)\n    # Importance\n    pd.read_csv(os.path.join(OUT_DIR, \"/kaggle/input/communication-devstack-dataset/A12_perm_importance_IF.csv\")).to_excel(xl, sheet_name=\"A12_perm_importance\", index=False)\n    # Stats test\n    pd.read_csv(os.path.join(OUT_DIR, \"/kaggle/input/communication-devstack-dataset/A20_bootstrap_ens_vs_if.csv\")).to_excel(xl, sheet_name=\"A20_bootstrap\", index=False)\n\nprint(\"Saved MASTER workbook:\", master_xlsx)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T11:36:19.096659Z","iopub.execute_input":"2025-10-14T11:36:19.096933Z","iopub.status.idle":"2025-10-14T11:36:19.278625Z","shell.execute_reply.started":"2025-10-14T11:36:19.096912Z","shell.execute_reply":"2025-10-14T11:36:19.277998Z"}},"outputs":[{"name":"stdout","text":"Saved MASTER workbook: /kaggle/working/MASTER_RESULTS_FOR_PAPER.xlsx\n","output_type":"stream"}],"execution_count":29},{"id":"abd30f5a","cell_type":"markdown","source":"## 19) Save Fullâ€‘Data Models for Deployment","metadata":{}},{"id":"b40ee35b","cell_type":"code","source":"\n# Save full models used for policy/scoring\nif JOBLIB_OK:\n    joblib.dump(iso_full, os.path.join(MODEL_DIR, \"deploy_IF.pkl\"))\n    joblib.dump(lof_full, os.path.join(MODEL_DIR, \"deploy_LOF.pkl\"))\n    joblib.dump(svm_full, os.path.join(MODEL_DIR, \"deploy_OCSVM.pkl\"))\n# Save weighted-ensemble weights\nsave_json({'weights': [0.5, 0.2, 0.3]}, os.path.join(MODEL_DIR, \"deploy_weighted_ensemble.json\"))\nprint(\"Saved deployable models in:\", MODEL_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T11:30:28.938126Z","iopub.execute_input":"2025-10-14T11:30:28.938879Z","iopub.status.idle":"2025-10-14T11:30:29.184590Z","shell.execute_reply.started":"2025-10-14T11:30:28.938853Z","shell.execute_reply":"2025-10-14T11:30:29.183583Z"}},"outputs":[{"name":"stdout","text":"Saved deployable models in: /kaggle/working/models\n","output_type":"stream"}],"execution_count":23},{"id":"14f5eb02","cell_type":"markdown","source":"\n## 20) Notes\n- All CV metrics use **synthetic labels generated only on validation folds** to avoid leakage.  \n- SHAP is optional and will be skipped if not available; **permutation importance** is always produced.  \n- Expect long runtime; you asked for the **full** ablation suite with model saving.  \n- All artifacts are under `/kaggle/working/`.\n","metadata":{}},{"id":"a42cfbf2-7c06-4973-a5ab-20c7d11e8c44","cell_type":"code","source":"import shutil, os\n\n# Path where Kaggle saves outputs\nOUT_DIR = \"/kaggle/working\"\n\n# Zip file name\nzip_path = \"/kaggle/working/output_results.zip\"\n\n# Remove old zip if exists\nif os.path.exists(zip_path):\n    os.remove(zip_path)\n\n# Create new zip (recursively includes all files in working dir)\nshutil.make_archive(zip_path.replace(\".zip\",\"\"), 'zip', OUT_DIR)\n\nprint(f\"âœ… Zipped all outputs to {zip_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T11:30:34.444042Z","iopub.execute_input":"2025-10-14T11:30:34.444334Z","iopub.status.idle":"2025-10-14T11:30:36.526974Z","shell.execute_reply.started":"2025-10-14T11:30:34.444314Z","shell.execute_reply":"2025-10-14T11:30:36.526158Z"}},"outputs":[{"name":"stdout","text":"âœ… Zipped all outputs to /kaggle/working/output_results.zip\n","output_type":"stream"}],"execution_count":24},{"id":"3864fb78-290d-43fd-97cf-a94ff1d32fab","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}